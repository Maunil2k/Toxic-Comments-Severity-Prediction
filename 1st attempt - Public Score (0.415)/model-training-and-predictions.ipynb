{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2161385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:38:08.508120Z",
     "iopub.status.busy": "2021-12-29T06:38:08.506010Z",
     "iopub.status.idle": "2021-12-29T06:38:22.015297Z",
     "shell.execute_reply": "2021-12-29T06:38:22.013811Z",
     "shell.execute_reply.started": "2021-12-29T06:24:31.935736Z"
    },
    "papermill": {
     "duration": 13.52921,
     "end_time": "2021-12-29T06:38:22.015502",
     "exception": false,
     "start_time": "2021-12-29T06:38:08.486292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6fb8d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:38:22.048224Z",
     "iopub.status.busy": "2021-12-29T06:38:22.047412Z",
     "iopub.status.idle": "2021-12-29T06:38:22.339168Z",
     "shell.execute_reply": "2021-12-29T06:38:22.339793Z",
     "shell.execute_reply.started": "2021-12-29T06:24:42.693280Z"
    },
    "papermill": {
     "duration": 0.310058,
     "end_time": "2021-12-29T06:38:22.339969",
     "exception": false,
     "start_time": "2021-12-29T06:38:22.029911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understand sentence several authors criticised...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks dont really mind attacks neighbor small...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29 october 2007 utc spinout article therefore ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010 formula one season</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>welcome hello wikipedia im one thousands edito...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  targets\n",
       "0  understand sentence several authors criticised...        0\n",
       "1  thanks dont really mind attacks neighbor small...        0\n",
       "2  29 october 2007 utc spinout article therefore ...        0\n",
       "3                            2010 formula one season        0\n",
       "4  welcome hello wikipedia im one thousands edito...        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/processedcsv-toxic-comments/final_data.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c71767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:38:22.375584Z",
     "iopub.status.busy": "2021-12-29T06:38:22.374133Z",
     "iopub.status.idle": "2021-12-29T06:38:22.378213Z",
     "shell.execute_reply": "2021-12-29T06:38:22.378792Z",
     "shell.execute_reply.started": "2021-12-29T06:24:42.979164Z"
    },
    "papermill": {
     "duration": 0.024642,
     "end_time": "2021-12-29T06:38:22.378980",
     "exception": false,
     "start_time": "2021-12-29T06:38:22.354338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45694, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d4d899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:38:22.419651Z",
     "iopub.status.busy": "2021-12-29T06:38:22.418325Z",
     "iopub.status.idle": "2021-12-29T06:38:22.430598Z",
     "shell.execute_reply": "2021-12-29T06:38:22.430025Z",
     "shell.execute_reply.started": "2021-12-29T06:24:42.986516Z"
    },
    "papermill": {
     "duration": 0.037758,
     "end_time": "2021-12-29T06:38:22.430719",
     "exception": false,
     "start_time": "2021-12-29T06:38:22.392961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45688, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7ca7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:38:22.464902Z",
     "iopub.status.busy": "2021-12-29T06:38:22.464066Z",
     "iopub.status.idle": "2021-12-29T06:39:12.843600Z",
     "shell.execute_reply": "2021-12-29T06:39:12.844259Z",
     "shell.execute_reply.started": "2021-12-29T06:24:43.009000Z"
    },
    "papermill": {
     "duration": 50.399439,
     "end_time": "2021-12-29T06:39:12.844430",
     "exception": false,
     "start_time": "2021-12-29T06:38:22.444991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('../input/glove-embeddings/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d52031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:39:12.879860Z",
     "iopub.status.busy": "2021-12-29T06:39:12.879036Z",
     "iopub.status.idle": "2021-12-29T06:39:12.888770Z",
     "shell.execute_reply": "2021-12-29T06:39:12.888162Z",
     "shell.execute_reply.started": "2021-12-29T06:25:28.426747Z"
    },
    "papermill": {
     "duration": 0.029752,
     "end_time": "2021-12-29T06:39:12.888921",
     "exception": false,
     "start_time": "2021-12-29T06:39:12.859169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0486b15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:39:12.935784Z",
     "iopub.status.busy": "2021-12-29T06:39:12.930276Z",
     "iopub.status.idle": "2021-12-29T06:39:17.627313Z",
     "shell.execute_reply": "2021-12-29T06:39:17.626600Z",
     "shell.execute_reply.started": "2021-12-29T06:25:28.443459Z"
    },
    "papermill": {
     "duration": 4.723554,
     "end_time": "2021-12-29T06:39:17.627474",
     "exception": false,
     "start_time": "2021-12-29T06:39:12.903920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len_tweet = train_df.comments.apply(lambda x: len(x.split())).max()\n",
    "\n",
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(train_df.comments)\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "encoded_tweet = tok.texts_to_sequences(train_df.comments)\n",
    "padded_tweet = pad_sequences(encoded_tweet, maxlen=max_len_tweet, padding='post')\n",
    "\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "\n",
    "tweet_embedding_matrix = np.zeros((vocab_size, 300)) #for 300 dimensions\n",
    "for word, i in tok.word_index.items():\n",
    "    t_embedding_vector = embeddings_index.get(word)\n",
    "    if t_embedding_vector is not None:\n",
    "        tweet_embedding_matrix[i] = t_embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3dfff00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:39:17.667018Z",
     "iopub.status.busy": "2021-12-29T06:39:17.666234Z",
     "iopub.status.idle": "2021-12-29T06:39:28.520833Z",
     "shell.execute_reply": "2021-12-29T06:39:28.521727Z",
     "shell.execute_reply.started": "2021-12-29T06:25:32.343265Z"
    },
    "papermill": {
     "duration": 10.879466,
     "end_time": "2021-12-29T06:39:28.521937",
     "exception": false,
     "start_time": "2021-12-29T06:39:17.642471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 06:39:17.696875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:17.698622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:17.699711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:17.700912: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-29 06:39:17.702149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:17.703219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:17.704247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:26.020707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:26.021797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:26.022698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 06:39:26.023575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14589 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1250, 300)         27639900  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1250, 256)         570368    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1250, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1250, 256)         1024      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1250, 128)         197120    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1250, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1250, 64)          49408     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1250, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 28,470,781\n",
      "Trainable params: 28,470,269\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_len_tweet, weights=[tweet_embedding_matrix], trainable=True))\n",
    "\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53de90d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:39:28.566792Z",
     "iopub.status.busy": "2021-12-29T06:39:28.565687Z",
     "iopub.status.idle": "2021-12-29T06:41:56.467993Z",
     "shell.execute_reply": "2021-12-29T06:41:56.466915Z",
     "shell.execute_reply.started": "2021-12-29T06:25:40.855739Z"
    },
    "papermill": {
     "duration": 147.930042,
     "end_time": "2021-12-29T06:41:56.468248",
     "exception": false,
     "start_time": "2021-12-29T06:39:28.538206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 06:39:28.767125: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-29 06:39:35.553210: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 143s 472ms/step - loss: 0.2436 - accuracy: 0.6106 - mae: 0.4634 - val_loss: 0.5181 - val_accuracy: 0.0000e+00 - val_mae: 0.7198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d23031bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'mae']\n",
    "             )\n",
    "\n",
    "model_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=3),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor = 0.1, patience=3, min_lr=1e-01),\n",
    "    keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5',monitor='val_loss', )\n",
    "]\n",
    "\n",
    "model.fit(padded_tweet, train_df.targets,\n",
    "          epochs=1,\n",
    "          batch_size= 128,\n",
    "          callbacks=model_callbacks,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          verbose = 1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a448f242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:41:56.708786Z",
     "iopub.status.busy": "2021-12-29T06:41:56.708070Z",
     "iopub.status.idle": "2021-12-29T06:41:56.812620Z",
     "shell.execute_reply": "2021-12-29T06:41:56.812011Z",
     "shell.execute_reply.started": "2021-12-29T06:29:01.955490Z"
    },
    "papermill": {
     "duration": 0.22615,
     "end_time": "2021-12-29T06:41:56.812823",
     "exception": false,
     "start_time": "2021-12-29T06:41:56.586673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1      732895  Looks like be have an abuser , can you please ...\n",
       "2     1139051  I confess to having complete (and apparently b...\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4     2084821  It is not just you. This is a laundry list of ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "test_df = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n",
    "results['comment_id'] = test_df['comment_id']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b74198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:41:57.058099Z",
     "iopub.status.busy": "2021-12-29T06:41:57.056968Z",
     "iopub.status.idle": "2021-12-29T06:41:57.060311Z",
     "shell.execute_reply": "2021-12-29T06:41:57.059754Z",
     "shell.execute_reply.started": "2021-12-29T06:29:45.863594Z"
    },
    "papermill": {
     "duration": 0.129533,
     "end_time": "2021-12-29T06:41:57.060444",
     "exception": false,
     "start_time": "2021-12-29T06:41:56.930911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+',\n",
    "        flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(html, '', text)\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32471a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:41:57.376446Z",
     "iopub.status.busy": "2021-12-29T06:41:57.375147Z",
     "iopub.status.idle": "2021-12-29T06:43:40.387622Z",
     "shell.execute_reply": "2021-12-29T06:43:40.388184Z",
     "shell.execute_reply.started": "2021-12-29T06:33:38.396625Z"
    },
    "papermill": {
     "duration": 103.208993,
     "end_time": "2021-12-29T06:43:40.388358",
     "exception": false,
     "start_time": "2021-12-29T06:41:57.179365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_df['text'] = test_df['text'].apply(lambda x: remove_URL(x))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: remove_emoji(x))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: remove_html(x))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "test_df['text'] = test_df['text'].apply(word_tokenize)\n",
    "\n",
    "test_df['text'] = test_df['text'].apply(lambda x: [word.lower() for word in x])\n",
    "\n",
    "test_df['text'] = test_df['text'].apply(lambda x: [word for word in x if word not in set(nltk.corpus.stopwords.words('english'))])\n",
    "\n",
    "test_df['text'] = [' '.join(map(str, l)) for l in test_df['text']]\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ceaa61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:43:40.667846Z",
     "iopub.status.busy": "2021-12-29T06:43:40.642918Z",
     "iopub.status.idle": "2021-12-29T06:43:41.359307Z",
     "shell.execute_reply": "2021-12-29T06:43:41.358611Z",
     "shell.execute_reply.started": "2021-12-29T06:34:52.262429Z"
    },
    "papermill": {
     "duration": 0.854688,
     "end_time": "2021-12-29T06:43:41.359479",
     "exception": false,
     "start_time": "2021-12-29T06:43:40.504791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len_test = test_df.text.apply(lambda x: len(x.split())).max()\n",
    "\n",
    "tok_test = Tokenizer()\n",
    "tok_test.fit_on_texts(test_df.text)\n",
    "vocab_size_test = len(tok_test.word_index) + 1\n",
    "encoded_test = tok_test.texts_to_sequences(test_df.text)\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_len_test, padding='post')\n",
    "\n",
    "vocab_size_test = len(tok_test.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ed7268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T06:43:41.599969Z",
     "iopub.status.busy": "2021-12-29T06:43:41.598761Z",
     "iopub.status.idle": "2021-12-29T06:44:01.189156Z",
     "shell.execute_reply": "2021-12-29T06:44:01.189727Z",
     "shell.execute_reply.started": "2021-12-29T06:36:22.668993Z"
    },
    "papermill": {
     "duration": 19.713586,
     "end_time": "2021-12-29T06:44:01.189908",
     "exception": false,
     "start_time": "2021-12-29T06:43:41.476322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(padded_test)\n",
    "results['score'] = preds\n",
    "results.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 365.728518,
   "end_time": "2021-12-29T06:44:04.810138",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-29T06:37:59.081620",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
